{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement: How have hits changed over the years?\n",
    "\n",
    "**The goal of this project is to examine how hits have changed over the years in terms of a song's specific features and its lyrics. We will focus on how hits have changed since 2008, but will specifically compare changes from the years 2008 to 2013 to 2018.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using Web API and Web Scraping methods to gather all of our data\n",
    "- Scraping from Billboard's Year-End Hot 100 Songs will provide us with songs to use as a proxy for hit songs.\n",
    "- Scraping from SongFacts will provide us with other songs that are not on the Year-End Hot 100 list for each year, but were released in the same year as each Hot 100 list was compiled.\n",
    "- Genius' API will provide us with song lyrics for the tracks we will use in our model.\n",
    "- Spotify's API will provide us with important audio features that we need for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy                     # Spotify's API packagelibrary\n",
    "import spotipy.oauth2 as oauth2    # Spotify's authorization sublibrary\n",
    "import lyricsgenius as genius      # Genius' API package library\n",
    "import json                        \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's scrape Billboard's Year-End Hot 100 Songs using BeautifulSoup\n",
    "- We will be scraping Year-End charts from 2008, 2013 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating URLs for Year-End Hot 100 Songs for years 2008, 2013 and 2018\n",
    "url_billboard_2008 = 'https://www.billboard.com/charts/year-end/2008/hot-100-songs'\n",
    "url_billboard_2013 = 'https://www.billboard.com/charts/year-end/2013/hot-100-songs'\n",
    "url_billboard_2018 = 'https://www.billboard.com/charts/year-end/2018/hot-100-songs'\n",
    "\n",
    "# Create a master list of all URLs \n",
    "billboard_master_url_list = [url_billboard_2008, url_billboard_2013, url_billboard_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes a URL and scrapes all track names from that specific year's Year-End Hot 100 list\n",
    "def get_track_names(url):\n",
    "    res = requests.get(url)                       # Instantiate a get request for the url\n",
    "    soup = BeautifulSoup(res.content, 'lxml')     # Instantiate a soup object\n",
    "    \n",
    "    soup_track_names = soup.find_all('div', {'class': 'ye-chart-item__title'})     # Soup object query for track names\n",
    "    track_names = []                                                               # Create an empty list to fill with track names\n",
    "    \n",
    "    # Create a for loop to iterate through each json row returned from the query\n",
    "    for i in range(len(soup_track_names)):              \n",
    "        stripped_title = soup_track_names[i].text.strip('\\n')          # Strip '\\n' from the track names\n",
    "        track_names.append(stripped_title)                             # Append the list with stripped title names\n",
    "        \n",
    "    return track_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes a URL and scrapes all artist names from that specific year's Year-End Hot 100 list\n",
    "def get_artist_names(url):\n",
    "    res = requests.get(url)                       # Instantiate a get request for the url\n",
    "    soup = BeautifulSoup(res.content, 'lxml')     # Instantiate a soup object\n",
    "    \n",
    "    soup_artist_names = soup.find_all('div', {'class': 'ye-chart-item__artist'})   # Soup object query for artist names\n",
    "    artist_names = []                                                              # Create an empty list to fill with artist names\n",
    "    \n",
    "    # Create a for loop to iterate through each json row returned from the query\n",
    "    for i in range(len(soup_artist_names)):              \n",
    "        stripped_artist = soup_artist_names[i].text.strip('\\n')        # Strip '\\n' from the artist names\n",
    "        artist_names.append(stripped_artist)                           # Append the list with stripped artist names\n",
    "        \n",
    "    return artist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variables for all hit songs and respective artists for years 2008, 2013 and 2018\n",
    "hit_songs_08 = get_track_names(url_billboard_2008)\n",
    "hit_artists_08 = get_artist_names(url_billboard_2008)\n",
    "\n",
    "hit_songs_13 = get_track_names(url_billboard_2013)\n",
    "hit_artists_13 = get_artist_names(url_billboard_2013)\n",
    "\n",
    "hit_songs_18 = get_track_names(url_billboard_2018)\n",
    "hit_artists_18 = get_artist_names(url_billboard_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, lets scrape songs that were not on the Year-End Hot 100 list from SongFacts\n",
    "- SongFacts is a website that provides expansive lists of all songs that were released in a given year in the US. Whether the site has successfully captured every single song release in the specified year is not 100% certain, but for the purposes of this project, the quantity of songs available is what we are going for. Similar to the steps taken above for scraping Billboard, we will proceed with a similar process for SongFacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating URLs for SongFacts browse pages for years 2008, 2013 and 2018\n",
    "url_songfacts_2008 = \"https://www.songfacts.com/browse/years/2008\"\n",
    "url_songfacts_2013 = \"https://www.songfacts.com/browse/years/2013\"\n",
    "url_songfacts_2018 = \"https://www.songfacts.com/browse/years/2018\"\n",
    "\n",
    "# Create a master list of all URLs\n",
    "songfacts_master_url_list = [url_songfacts_2008, url_songfacts_2013, url_songfacts_2018]\n",
    "\n",
    "# Instantiating a user agent for SongFacts web scrape\n",
    "headers = {'User-agent': 'danhyunkim'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will create separate functions to scrape all song and artist names for each individual year. We tried creating one function to do this for each year, but ran into issues when trying to scrape multiple pages for each year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate empty lists to fill with all song and artist names from 2008\n",
    "sf_songs_2008 = []\n",
    "sf_artists_2008 = []\n",
    "\n",
    "# Define the scraping function for 2008\n",
    "# Inputs are the url, a song list and an artist list\n",
    "def get_sf_songs_2008(url, song_list, artist_list):\n",
    "    res_url = requests.get(url, headers=headers)         # Create a get request for the url\n",
    "    sf_soup = BeautifulSoup(res_url.content, 'lxml')     # Create a soup object for the url\n",
    "\n",
    "    # This range is specific to the json data that the below query delivers\n",
    "    # Each page has 100 songs with their respective artists which starts at index 39 and ends at index 138\n",
    "    for i in range(39, 139):\n",
    "        \n",
    "        # Query for getting json data for song and artist names\n",
    "        # The query will return a list in this format: ['song name - artist name']\n",
    "        # The code will replace the hyphen with a comma and split on the comma to create two separate strings as such: ['song name', 'artist name']\n",
    "        song_and_artist = sf_soup.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "        \n",
    "        # Append the first item of each list created to empty song list\n",
    "        sf_songs_2008.append(song_and_artist[0])              \n",
    "        \n",
    "        # Append the second item of each list created to empty artist list and replace spaces with empty string\n",
    "        sf_artists_2008.append(song_and_artist[1].replace(' ', ''))        \n",
    "        \n",
    "        # Break this for loop here because a new for loop is necessary for the remaining pages of songs\n",
    "        break\n",
    "        \n",
    "    # New for loop to scrape songs and artists from page 2 through 21\n",
    "    # This range is specific for the year 2008\n",
    "    # Using tqdm progress bar to track run time and progress\n",
    "    for i in tqdm(range(2,22)):\n",
    "        \n",
    "        # Base url that will be used to create the URL for each page\n",
    "        url_next_page = 'https://www.songfacts.com/browse/years/2008/page'+str(i)\n",
    "        \n",
    "        res_url_next_page = requests.get(url_next_page, headers=headers)         # URL specific get request\n",
    "        sf_soup_next_page = BeautifulSoup(res_url_next_page.content, 'lxml')     # URL specific soup object\n",
    "        \n",
    "        # Same scraping process as above\n",
    "        for i in range(39, 139):\n",
    "            song_and_artist = sf_soup_next_page.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "            sf_songs_2008.append(song_and_artist[0])\n",
    "            sf_artists_2008.append(song_and_artist[1])\n",
    "        \n",
    "        # 5 second break before rerunning the for loop\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The intuition behind the 2013 and 2018 scraping functions follows the same logic as the 2008 scraping function so commenting is excluded unless otherwise noted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_songs_2013 = []\n",
    "sf_artists_2013 = []\n",
    "\n",
    "def get_sf_songs_2013(url, song_list, artist_list):\n",
    "    res_url = requests.get(url, headers=headers)\n",
    "    sf_soup = BeautifulSoup(res_url.content, 'lxml')\n",
    "\n",
    "    for i in range(39, 139):\n",
    "        song_and_artist = sf_soup.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "        sf_songs_2013.append(song_and_artist[0])\n",
    "        sf_artists_2013.append(song_and_artist[1].replace(' ', ''))\n",
    "            \n",
    "        break\n",
    "        \n",
    "    # New for loop to scrape songs and artists from page 2 through 29\n",
    "    # This range is specific for the year 2013      \n",
    "    for i in tqdm(range(2,30)):\n",
    "        url_next_page = 'https://www.songfacts.com/browse/years/2013/page'+str(i)\n",
    "        \n",
    "        res_url_next_page = requests.get(url_next_page, headers=headers)\n",
    "        sf_soup_next_page = BeautifulSoup(res_url_next_page.content, 'lxml')\n",
    "\n",
    "        for i in range(39, 139):\n",
    "            song_and_artist = sf_soup_next_page.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "            sf_songs_2013.append(song_and_artist[0])\n",
    "            sf_artists_2013.append(song_and_artist[1])\n",
    "            \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_songs_2018 = []\n",
    "sf_artists_2018 = []\n",
    "\n",
    "def get_sf_songs_2018(url, song_list, artist_list):\n",
    "    res_url = requests.get(url, headers=headers)\n",
    "    sf_soup = BeautifulSoup(res_url.content, 'lxml')\n",
    "\n",
    "    for i in range(39, 139):\n",
    "        song_and_artist = sf_soup.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "        sf_songs_2018.append(song_and_artist[0])\n",
    "        sf_artists_2018.append(song_and_artist[1].replace(' ', ''))\n",
    "            \n",
    "        break\n",
    "        \n",
    "    # New for loop to scrape songs and artists from page 2 through 15\n",
    "    # This range is specific for the year 2018     \n",
    "    for i in tqdm(range(2,16)):\n",
    "        url_next_page = 'https://www.songfacts.com/browse/years/2013/page'+str(i)\n",
    "        \n",
    "        res_url_next_page = requests.get(url_next_page, headers=headers)\n",
    "        sf_soup_next_page = BeautifulSoup(res_url_next_page.content, 'lxml')\n",
    "\n",
    "        for i in range(39, 139):\n",
    "            song_and_artist = sf_soup_next_page.find_all('li')[i].text.replace('-', ',').split(',')\n",
    "            sf_songs_2018.append(song_and_artist[0])\n",
    "            sf_artists_2018.append(song_and_artist[1])\n",
    "            \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function for year 2008 \n",
    "get_sf_songs_2008(url_songfacts_2008, sf_songs_2008, sf_artists_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function for year 2013 \n",
    "get_sf_songs_2013(url_songfacts_2013, sf_songs_2013, sf_artists_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function for year 2018 \n",
    "get_sf_songs_2018(url_songfacts_2018, sf_songs_2018, sf_artists_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n",
      "1992\n"
     ]
    }
   ],
   "source": [
    "# Check the length of song and artist list of 2008\n",
    "print(len(sf_songs_2008))\n",
    "print(len(sf_artists_2008))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2785\n",
      "2785\n"
     ]
    }
   ],
   "source": [
    "# Check the length of song and artist list of 2013\n",
    "print(len(sf_songs_2013))\n",
    "print(len(sf_artists_2013))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401\n",
      "1401\n"
     ]
    }
   ],
   "source": [
    "# Check the length of song and artist list of 2018\n",
    "print(len(sf_songs_2018))\n",
    "print(len(sf_artists_2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have a sample of non-Billboard songs. The quantity of songs and artists for each year are different and does not reflect the total number of songs released in those respective years because SongFacts limits us from obtaining more.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's access Genius' API for song lyrics for all of our songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Genius object\n",
    "genius = genius.Genius(client_access_token='79kKz5PXL7Ych9sufcqL1nWlo73O8Si4YJjqZIfYsjwhMs1AELP5v3OHU5QxWUso', \n",
    "              response_format='plain',         # Format of response is plain text\n",
    "              timeout=5, sleep_time=0.5, \n",
    "              remove_section_headers=True,     # Remove headers such as [Intro], [Verse], [Chorus]n etc.\n",
    "              skip_non_songs=True,             # Skip items that are not songs\n",
    "              verbose=True)                    # Print search text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get lyrics from Genius' API\n",
    "# The inputs are a song list, an artist list and an empty lyrics list to append the lyrics to\n",
    "def get_lyrics(song_list, artist_list, lyrics_list):\n",
    "    \n",
    "    # Create a for loop that will iterate through the songs and artists in the song and artist list\n",
    "    for song, artist in zip(song_list, artist_list):\n",
    "        \n",
    "        # Create a try and except statement in case there are certain songs that Genius does not have the lyrics for\n",
    "        try:  \n",
    "            # Genius API query which pulls the lyrics of the song given the song name and artist name\n",
    "            lyrics = genius.search_song(song, artist=artist).lyrics.replace('\\n', ' ').replace('.', '').replace(',', '').replace('-', ' ').replace(\"'\", '').replace('\"', '').replace('?', '')\n",
    "            \n",
    "            # Append the lyrics to the empty lyrics list\n",
    "            lyrics_list.append(lyrics)\n",
    "            \n",
    "            # 3 second break before rerunning the for loop\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of billboard hits for 2008\n",
    "billboard_lyrics_08 = []\n",
    "\n",
    "# Run function to get lyrics for 2008 billboard hits\n",
    "get_lyrics(hit_songs_08, hit_artists_08, billboard_lyrics_08)\n",
    "\n",
    "# Check length of lyrics list\n",
    "len(billboard_lyrics_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of billboard hits for 2013\n",
    "billboard_lyrics_13 = []\n",
    "\n",
    "# Run function to get lyrics for 2013 billboard hits\n",
    "get_lyrics(hit_songs_13, hit_artists_13, billboard_lyrics_13)\n",
    "\n",
    "len(billboard_lyrics_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of billboard hits for 2018\n",
    "billboard_lyrics_18 = []\n",
    "\n",
    "# Run function to get lyrics for 2018 billboard hits\n",
    "get_lyrics(hit_songs_18, hit_artists_18, billboard_lyrics_18)\n",
    "\n",
    "len(billboard_lyrics_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1947"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of songfacts songs for 2008\n",
    "songfacts_lyrics_08 = []\n",
    "\n",
    "# Run function to get lyrics for 2008 songfacts songs and append it to empty list\n",
    "# We are only feeding in the first 1401 songs and artists into the API to stay consistent\n",
    "# with the length of songs and artists in the 2018 songfacts list\n",
    "get_lyrics(sf_songs_2008, sf_artists_2008, songfacts_lyrics_08)\n",
    "\n",
    "len(songfacts_lyrics_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of songfacts songs for 2013\n",
    "songfacts_lyrics_13 = []\n",
    "\n",
    "# Run function to get lyrics for 2013 songfacts songs and append it to empty list\n",
    "# We are only feeding in the first 1401 songs and artists into the API to stay consistent\n",
    "# with the length of songs and artists in the 2018 songfacts list\n",
    "get_lyrics(sf_songs_2013, sf_artists_2013, songfacts_lyrics_13)\n",
    "\n",
    "len(songfacts_lyrics_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an empty list to fill with lyrics of songfacts songs for 2018\n",
    "songfacts_lyrics_18 = []\n",
    "\n",
    "# Run function to get lyrics for 2018 songfacts songs and append it to empty list\n",
    "get_lyrics(sf_songs_2018, sf_artists_2018, songfacts_lyrics_18)\n",
    "\n",
    "len(songfacts_lyrics_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let's access Spotify's API for audio features of our songs\n",
    "- Spotify provides us with innovative features that comprise a song. These features include danceability, energy, musical key of the song, loudness, mode, speechiness, acousticness, instrumentalness, liveliness, valence, tempo, duration in milliseconds and time signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up credentials and token for API environment\n",
    "credentials = oauth2.SpotifyClientCredentials(\n",
    "    client_id='24ae571f5509439a800b0bc9f45b9a3d',       # Client ID provided from developer account page\n",
    "    client_secret='d75b449fae6c460f8482f4d83227b563')   # Client Secret ID provided from developer account page\n",
    "                                                        # Client Secret ID has since been changed \n",
    "token = credentials.get_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spotify object\n",
    "spotify = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have all of our songs, we need to get their URIs in order to extract the important audio features from Spotify's API. We created a function that will get the URI for each song and use it to obtain its audio features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will get audio features for songs from Spotify's API\n",
    "# The inputs are a song list \n",
    "def get_features(song_list):\n",
    "    \n",
    "    # Instantiate a features list to return\n",
    "    features_list_to_return = []\n",
    "    \n",
    "    # Create a for loop that will iterate through each song in the song list that we pass in\n",
    "    # Utilize tqdm package to show progress bar of our for loop since list iterable is long\n",
    "    for song in tqdm(song_list):\n",
    "        \n",
    "        # Create a try and except statement in the case there are songs that do not exist in Spotify's library\n",
    "        # thus do not have a URI\n",
    "        try:\n",
    "            # Spotify query that retrieves a song's URI based on a given track name\n",
    "            uri = spotify.search(song, limit=1, offset=0, type='track')['tracks']['items'][0]['uri']\n",
    "\n",
    "            # Spotify API query that will retrieve audio features with a given URI\n",
    "            features = spotify.audio_features(uri)\n",
    "\n",
    "            # Append the audio features to the empty features list\n",
    "            features_list_to_return.append(features)\n",
    "\n",
    "        # If the song does not exist in the Spotify library we will pass over it\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 2 second pause before continuing on with the loop    \n",
    "        time.sleep(2)\n",
    "        \n",
    "    # Return the features list\n",
    "    return features_list_to_return\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize the function above to get audio features for all of our songs through Spotify's API.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_features_2018 = get_features(hit_songs_18)\n",
    "\n",
    "len(billboard_features_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songfacts_features_2018 = get_features(sf_songs_2018)\n",
    "\n",
    "len(songfacts_features_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_features_2013 = get_features(hit_songs_13)\n",
    "\n",
    "len(billboard_features_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songfacts_features_2013 = get_features(sf_songs_2013)\n",
    "\n",
    "len(songfacts_features_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_features_2008 = get_features(hit_songs_08)\n",
    "\n",
    "len(billboard_features_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songfacts_features_2008 = get_features(sf_songs_2008)\n",
    "\n",
    "len(songfacts_features_2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We finally have all of our data. Now let's put the data into DataFrame format for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio Features DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that creates a dataframe given a features list\n",
    "def dataframe(features_list):\n",
    "    \n",
    "    # Our features list is a list of dictionaries within a larger list so we need to\n",
    "    # create a dataframe list to append the individual audio features dataframes for each song\n",
    "    df_list = []\n",
    "    \n",
    "    # Create a for loop that will iterate through each song's audio features\n",
    "    for i in range(len(features_list)):\n",
    "        \n",
    "        # Create dataframe for the ith song\n",
    "        features_list_df = pd.DataFrame(features_list[i], columns = features_list[0][0].keys())\n",
    "        \n",
    "        # Append dataframe to the dataframe list\n",
    "        df_list.append(features_list_df)\n",
    "        \n",
    "    # Concatenate all dataframes in the dataframe list and return the master dataframe\n",
    "    master_df = pd.concat(df_list)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new function is identical to the function above except for the try and except statements\n",
    "# We discovered that certain song features in the songfacts features list is not in the correct shape\n",
    "# to be made into a dataframe so we pass over those songs with the except statement\n",
    "def dataframe2(features_list):\n",
    "    df_list = []\n",
    "    for i in range(len(features_list)):\n",
    "        try:\n",
    "            features_list_df = pd.DataFrame(features_list[i], columns = features_list[0][0].keys())\n",
    "            df_list.append(features_list_df)\n",
    "        except:\n",
    "            pass\n",
    "    master_df = pd.concat(df_list)\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the dataframe function on each year's list of audio features for our hit songs and our non-hit songs and store them as csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_features_2018_df = dataframe(billboard_features_2018)\n",
    "billboard_features_2018_df.to_csv('./data/2018_billboard_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_features_2013_df = dataframe(billboard_features_2013)\n",
    "billboard_features_2013_df.to_csv('./data/2013_billboard_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_features_2008_df = dataframe(billboard_features_2008)\n",
    "billboard_features_2008_df.to_csv('./data/2008_billboard_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_features_18_df = dataframe2(songfacts_features_2018)\n",
    "songfacts_features_18_df.to_csv('./data/18_songfacts_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_features_2013_df = dataframe2(songfacts_features_2013)\n",
    "songfacts_features_2013_df.to_csv('./data/2013_songfacts_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_features_2008_df = dataframe2(songfacts_features_2008)\n",
    "songfacts_features_2008_df.to_csv('./data/2008_songfacts_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Song Lyrics DataFrames**\n",
    "\n",
    "**Create dataframes for each year's song lyrics for our hit songs and non-hit songs and store them as csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_lyrics_08_df = pd.DataFrame(billboard_lyrics_08, columns = ['lyrics'])\n",
    "billboard_lyrics_08_df.to_csv('./data/2008_billboard_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_lyrics_13_df = pd.DataFrame(billboard_lyrics_13, columns = ['lyrics'])\n",
    "billboard_lyrics_13_df.to_csv('./data/2013_billboard_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_lyrics_18_df = pd.DataFrame(billboard_lyrics_18, columns = ['lyrics'])\n",
    "billboard_lyrics_18_df.to_csv('./data/2018_billboard_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_lyrics_08_df = pd.DataFrame(songfacts_lyrics_08, columns = ['lyrics'])\n",
    "songfacts_lyrics_08_df.to_csv('./data/2008_songfacts_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_lyrics_13_df = pd.DataFrame(songfacts_lyrics_13, columns = ['lyrics'])\n",
    "songfacts_lyrics_13_df.to_csv('./data/2013_songfacts_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "songfacts_lyrics_18_df = pd.DataFrame(songfacts_lyrics_18, columns = ['lyrics'])\n",
    "songfacts_lyrics_18_df.to_csv('./data/2018_songfacts_lyrics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
